from flask import Flask, request, abort 
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
import openai
import traceback
import os
import json
import random 
from datetime import datetime
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document 



os.environ["TOKENIZERS_PARALLELISM"] = "false"


# GPT API Key è¨­å®šï¼ˆopenai 0.28.1 å¯«æ³•ï¼‰
openai.api_key = 'sk-Y6eY0OQ0ffzNHRow3639F5C9E29e4c4a9fEb9d6545DaC944'
openai.api_base = 'https://free.v36.cm/v1'  # è‡ªè¨‚ API server URL


# LINE è¨­å®š
CHANNEL_SECRET = 'd61f3ddbed2bca885f904047a010dafe'
CHANNEL_ACCESS_TOKEN = 'BmwXbOvc7uqDhjRxRC5MmaF9XH0QuMk+sXKL5Dp8yTqqFLCoq7nRNjj4TVt0mZSs2BZBoRK6UYoAY8Y2D1L2iVizgzRwU3Q2QblOcdFlf5/d61RLlvcB66gGoyqRQxvLw1KCwLF+/WNVioFp5IQ9SgdB04t89/1O/w1cDnyilFU='


line_bot_api = LineBotApi(CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(CHANNEL_SECRET)

vectorstore = None

def load_embedding_model():
    return HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L3-v2")

# === STEP 2: è®€å– TXT æª” ä¸¦åˆ‡å‰² ===
def load_static_document():
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    LARGE_TEXT = """
æˆ€æ„›å¼å°è³¼ AI â€• LINE å°è©±å¼•å°çœ‹æˆ¿æ©Ÿå™¨â¼ˆ
1. åœ˜éšŠä»‹ç´¹
æˆ‘å€‘çš„åœ˜éšŠç”±å…·æœ‰è±å¯Œæˆ¿åœ°ç”¢ç¶“é©—çš„å°ˆæ¥­æˆ¿ä»²å’Œé ‚å°–çš„AIæŠ€è¡“å°ˆå®¶çµ„æˆã€‚åœ˜éšŠä¸­åŒ…å«å¤šåæ“æœ‰â¼ˆâ¼¯æ™ºæ…§
èˆ‡â¾ƒç„¶èªâ¾”è™•ç†ï¼ˆNLPï¼‰èƒŒæ™¯çš„æŠ€è¡“â¼ˆå“¡ï¼Œè‡´â¼’æ–¼å°‡å…ˆé€²çš„AIæŠ€è¡“æ‡‰â½¤æ–¼æˆ¿åœ°ç”¢â¾æ¥­ï¼Œæä¾›å‰µæ–°â½½æœ‰æ•ˆ
çš„è§£æ±ºâ½…æ¡ˆã€‚
2. â½¬æ¨™å®¢ç¾¤èˆ‡ç—›é»
â½¬æ¨™å®¢ç¾¤
æ½›åœ¨è²·å®¶å’Œç§Ÿå®¢
æˆ¿åœ°ç”¢ä¸­ä»‹å…¬å¸
ç—›é»
é˜²è©é¨™éœ€æ±‚ï¼šç·šä¸Šçœ‹æˆ¿è©é¨™äº‹ä»¶é »ç™¼ï¼Œæ¶ˆè²»è€…ä¿¡ä»»åº¦ä½ã€‚
å°è³¼è½‰æ›ä½ï¼šå‚³çµ±æˆ¿åœ°ç”¢å°è³¼â½…å¼é›£ä»¥å¸å¼•å’Œè½‰åŒ–é¡§å®¢ã€‚
3. AI æŠ€è¡“é‹â½¤
æƒ…ç·’åµæ¸¬ NLP
åˆ©â½¤â¾ƒç„¶èªâ¾”è™•ç†æŠ€è¡“ï¼Œåˆ†æâ½¤â¼¾æƒ…ç·’ï¼Œæä¾›å€‹æ€§åŒ–çš„çœ‹æˆ¿å»ºè­°ã€‚
å°è©±å¼•å°æ¨¡å‹
æ™ºèƒ½å°è©±ç³»çµ±èƒ½å¤ æ¨¡æ“¬çœŸâ¼ˆäº’å‹•ï¼Œå¼•å°â½¤â¼¾é€²â¾ä¸‹â¼€æ­¥æ“ä½œï¼Œå¢åŠ åƒèˆ‡åº¦ã€‚
4. ç¨ç‰¹ç«¶çˆ­å„ªå‹¢ä¸€
æˆ€æ„›è©±è¡“ï¼šå°‡æˆ€æ„›è©±è¡“èâ¼Šå°è©±ï¼Œå¼•ç™¼â½¤â¼¾æƒ…æ„Ÿå…±é³´ã€‚
æˆ¿åœ°ç”¢å°è³¼èåˆï¼šçµåˆå°ˆæ¥­æˆ¿åœ°ç”¢çŸ¥è­˜ï¼Œæä¾›ç²¾æº–çš„çœ‹æˆ¿å»ºè­°ã€‚
5.ç¨ç‰¹ç«¶çˆ­å„ªå‹¢äºŒ
1. æˆ€æ„›å¼å°è©±æ¦‚å¿µï¼šæ¡ç”¨ã€Œåƒè·Ÿå¥³æœ‹å‹èªªè©±ã€çš„èªæ°£ã€Œçµ¦äºˆæ„Ÿæ€§èˆ‡åŒç†ã€çš„æˆåˆ†ï¼Œæ‰“ç ´å‚³çµ± bot å½±åƒç„¡æ°£ã€èªçœŸçš„é©—ç·´ã€‚
2. å°ˆæ¥­çš„æˆ¿åœ°ç”¢åˆ†ææŠ€è¡“ï¼šæ­é…æˆ‘å€‘åœ˜éšŠçš„æˆ¿åœ°ç”¢å„ªå‹¢ï¼Œè¼‰å…¥å¾ˆå¤šé‡å°åœ°å€ã€ç”¢æ¬Šã€ç¶“é©—å…§å®¹ï¼Œè®“å°è©±ä¸å†æ²’æœ‰åº•æ°´ï¼Œæœ‰èƒ½åŠ›æä¾›å°ˆæ¥­æŒ‡å°ã€‚
6. é æœŸæ•ˆç›Š
æâ¾¼é ç´„çœ‹æˆ¿ç‡ï¼šé€šéæ™ºèƒ½å¼•å°æâ¾¼çœ‹æˆ¿é ç´„çš„è½‰åŒ–ç‡ã€‚
é™ä½è©é¨™â¾µéšªï¼šåŠ å¼·â½¤â¼¾è­˜åˆ¥èˆ‡ä¿¡ä»»ï¼Œæ¸›å°‘è©é¨™äº‹ä»¶ã€‚
7. ä½¿â½¤æƒ…å¢ƒå±•â½°
æ¨¡æ“¬LINEå°è©±ç•Œâ¾¯ï¼Œå±•â½°AIå¦‚ä½•èˆ‡â½¤â¼¾é€²â¾äº’å‹•ï¼Œå¼•å°å…¶çœ‹æˆ¿æ±ºç­–ã€‚
8. å•†æ¥­æ¨¡å¼èˆ‡æ“´å±•æ€§
SaaSæ¨¡å¼ï¼šæä¾›è»Ÿé«”å³æœå‹™ï¼Œè®“æ›´å¤šæˆ¿åœ°ç”¢å…¬å¸è¼•é¬†æ¥â¼Šã€‚
æˆ¿ä»²ç³»çµ±APIæ•´åˆï¼šèˆ‡ç¾æœ‰æˆ¿ä»²ç³»çµ±ç„¡ç¸«æ•´åˆï¼Œæâ¾¼æ“ä½œæ•ˆç‡ã€‚
9. ç¤¾æœƒå½±éŸ¿èˆ‡è½åœ°åƒ¹å€¼
æå‡ä¿¡ä»»èˆ‡å®‰å…¨ï¼šå»ºâ½´æ›´å®‰å…¨çš„ç·šä¸Šçœ‹æˆ¿ç’°å¢ƒï¼Œå¢å¼·â½¤â¼¾ä¿¡ä»»ã€‚
ä¿ƒé€²æˆ¿åœ°ç”¢å¸‚å ´å¥åº·ç™¼å±•ï¼šé€šéæŠ€è¡“å‰µæ–°ï¼Œæ¨å‹•æ•´å€‹â¾æ¥­çš„é€²æ­¥ã€‚
10. çµèªèˆ‡å‘¼ç±²â½€æŒ
æˆ€æ„›å¼å°è³¼ AI å°‡æˆç‚ºæˆ¿åœ°ç”¢â¾æ¥­çš„è®Šâ¾°â¼’é‡ã€‚æˆ‘å€‘èª é‚€å„ç•Œâ½€æŒèˆ‡åˆä½œï¼Œå…±åŒæ¨å‹•é€™â¼€å‰µæ–°æŠ€è¡“çš„è½
åœ°èˆ‡æ™®åŠã€‚è®“æˆ‘å€‘æ”œâ¼¿å‰µé€ æ›´æ™ºèƒ½ã€æ›´å®‰å…¨çš„çœ‹æˆ¿é«”é©—ã€‚
"""
    chunks = splitter.split_text(LARGE_TEXT)
    return [Document(page_content=chunk) for chunk in chunks]

# === STEP 4: å»ºç«‹å‘é‡è³‡æ–™åº« ===
def create_vectorstore(chunks, embedding_model):
    return FAISS.from_documents(chunks, embedding_model)


# === STEP 5: å•ç­”éšæ®µï¼šæŸ¥è©¢ FAISS ä¸¦é¤µçµ¦ GPT ===
def ask_gpt_with_context(query: str, vectorstore: FAISS) -> str:
    docs = vectorstore.similarity_search(query, k=3)
    context = "\n\n".join([doc.page_content for doc in docs])
    system_prompt = "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çŸ¥è­˜åŠ©ç†ï¼Œè«‹æ ¹æ“šä¸‹åˆ—å…§å®¹å›ç­”å•é¡Œï¼š"
    user_prompt = f"å…§å®¹ï¼š\n{context}\n\nå•é¡Œï¼š{query}"
    
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.98,
        max_tokens=300,
    )
    return response["choices"][0]["message"]["content"].strip()





app = Flask(__name__)






@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    print(f"[Webhook æ¥æ”¶åˆ°è¨Šæ¯] Body:\n{body}")  # å°å‡ºè¨Šæ¯å…§å®¹ä»¥ç¢ºèª

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        print("[ç°½ç« éŒ¯èª¤] Signature ç„¡æ•ˆ")
        abort(400)

    return 'OK'

@app.before_first_request
def build_vectorstore():
    global vectorstore
    if vectorstore is None:  # ç¢ºä¿åªå»ºä¸€æ¬¡
        print("ğŸ” è¼‰å…¥è³‡æ–™èˆ‡å»ºç«‹å‘é‡åº«...")
        embeddings = load_embedding_model()
        print("ğŸ” è®€å– TXT æª” ä¸¦åˆ‡å‰²...")
        docs = load_static_document()
        print("ğŸ” å»ºç«‹å‘é‡è³‡æ–™åº«...") 
        vectorstore = FAISS.from_documents(docs, embeddings)




@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    global vectorstore
    user_input = event.message.text
    user_id = event.source.user_id

    if vectorstore is None:
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="ç³»çµ±å‰›å•Ÿå‹•ï¼Œæ­£åœ¨è¼‰å…¥çŸ¥è­˜åº«ï¼Œè«‹ç¨å¾Œå¹¾ç§’å†è©¦ ğŸ™")
        )
        return
    
    try:          
        # æ‰€æœ‰è¨Šæ¯éƒ½ç”¨å‘é‡è³‡æ–™åº«æŸ¥æ‰¾å…§å®¹ + GPT å›ç­”
        reply = ask_gpt_with_context(user_input, vectorstore)

        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=reply)
        )

        print(f"[ä½¿ç”¨è€… ID] {user_id}")
        print(f"[ä½¿ç”¨è€…æå•] {user_input}")
        print(f"[AI å›ç­”] {reply}")

    except Exception as e:
        print("âš ï¸ éŒ¯èª¤ç™¼ç”Ÿï¼š", e)
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="æŠ±æ­‰ï½å‰›å‰›æœ‰é»å°ç‹€æ³ï¼Œå“¥å“¥å¯ä»¥å†èªªä¸€æ¬¡å—ï¼Ÿ")
        )



if __name__ == "__main__":
    print("[å•Ÿå‹•] Flask App åŸ·è¡Œä¸­")
    app.run(host="0.0.0.0", port=5000)






