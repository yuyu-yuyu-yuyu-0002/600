from flask import Flask, request, abort 
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
import openai
import traceback
import os
import json
import random 
from datetime import datetime
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document 



os.environ["TOKENIZERS_PARALLELISM"] = "false"


# GPT API Key è¨­å®šï¼ˆopenai 0.28.1 å¯«æ³•ï¼‰
openai.api_key = 'sk-Y6eY0OQ0ffzNHRow3639F5C9E29e4c4a9fEb9d6545DaC944'
openai.api_base = 'https://free.v36.cm/v1'  # è‡ªè¨‚ API server URL


# LINE è¨­å®š
CHANNEL_SECRET = 'd61f3ddbed2bca885f904047a010dafe'
CHANNEL_ACCESS_TOKEN = 'BmwXbOvc7uqDhjRxRC5MmaF9XH0QuMk+sXKL5Dp8yTqqFLCoq7nRNjj4TVt0mZSs2BZBoRK6UYoAY8Y2D1L2iVizgzRwU3Q2QblOcdFlf5/d61RLlvcB66gGoyqRQxvLw1KCwLF+/WNVioFp5IQ9SgdB04t89/1O/w1cDnyilFU='


line_bot_api = LineBotApi(CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(CHANNEL_SECRET)

vectorstore = None

def load_embedding_model():
    return HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L3-v2")

# === STEP 2: è®€å– TXT æª” ä¸¦åˆ‡å‰² ===
def load_static_document():
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    LARGE_TEXT = """
ã€æˆ€æ„›å¼å°è²· AI ï¼ LINE å°è©±å¼•å°çœ‹æˆ¿æ©Ÿå™¨äººã€‘
ç¬¬ä¸€ç« ï¼šåœ˜éšŠä»‹ç´¹
æˆ‘å€‘çš„åœ˜éšŠç”±å…©å¤§çµ„æˆå“¡æ§‹æˆï¼šä¸€çµ„æ˜¯å…·æœ‰åå¹´ä»¥ä¸Šç¶“é©—çš„æˆ¿åœ°ç”¢ç¶“ç´€äººã€æ–½å·¥é ç®—å¸«ã€åœ°æ¨“é–‹ç™¼é¡§å•ï¼Œå¦ä¸€çµ„å‰‡æ˜¯é ç ”è¼ƒä¹…çš„ AI æŠ€è¡“å°ˆå®¶ã€‚æˆ‘å€‘ç¶“éå¹¾å€‹æœˆåˆä½œå¯¦è¸ï¼Œä»¥ã€Œæ€§æ„Ÿã€æ™ºæ…§ã€å¯¦ç”¨ã€ç‚ºè¨­è¨ˆæ ¹åŸºï¼Œå°‡ç²¾æ·»çš„æƒ…æ„Ÿå°è©±ã€ä¸Šæ‰‹çš„ NLP æŠ€è¡“èˆ‡å°ˆæ¥­æˆ¿åœ°ç”¢è³‡è¨Šå®Œç¾èåˆï¼Œæ‰“é€ ä¸€å€‹åˆ¥æ–¼ä»¥å¾€çš„ LINE çœ‹æˆ¿å°è²·æ©Ÿå™¨äººã€‚
ç¬¬äºŒç« ï¼šç›®æ¨™å®¢ç¾£èˆ‡ç—›é»åˆ†æ
æˆ‘å€‘æ‰€å°æ‡‰çš„ç›®æ¨™å®¢ç¾£ä¸»è¦åˆ†ç‚ºä¸‰é¡ï¼š
1. æƒ³çœ‹æˆ¿ä½†æ€•è¢«é¨™çš„ä¸­å¹´æˆ–ç¤¾æœƒæ–°äºº
2. å°ˆæ¥­ç¶“ç´€æœ‰æ•ˆå°å°çš„æœ€çµ•å¥½å‹•åŠ›
3. æˆ¿åœ°ç”¢ä¸­ä»‹å…¬å¸å¸Œæœ›çµ¦å®¢æˆ¶æä¾›æ›´å¥½çš„åŸºç¤æœå‹™
è€Œä»–å€‘çš„å…±åŒç—›é»ï¼Œå‰‡åŒ…æ‹¬ï¼š
* è²©æˆ¿é¨™å©¢ç›ªæœ‰ä¹‹ä¸ç½µï¼Œäººå€‘å°ç·šä¸Šçœ‹æˆ¿ä¿¡ä»»åº¦ä½
* å‚³çµ±æ‰¾æˆ¿éç¨‹ç¹è¤‡ä¸”æ—©å·²ç„¡æ³•æ»¿è¶³ç¾ä»£äººç†±æ„Ÿå¼äº’å‹•å’Œé€Ÿåº¦éœ€æ±‚
* å¤šæ•¸ç¶²ç«™æä¾›è³‡è¨Šåˆ†æ•£ï¼Œä¸æ˜“æ¯”è¼ƒï¼Œæ–¼æ˜¯ç¸½ç®—é€€æ­¥
ç¬¬ä¸‰ç« ï¼šAI æŠ€è¡“æ‡‰ç”¨é—œéµ
1. æƒ…ç·’è¾¨è­˜ (Sentiment Analysis)ï¼šç³»çµ±åˆ©ç”¨ NLP åˆ†æç”¨æˆ¶å£æ°£ã€èªæ°£èˆ‡è®šè²¬ç¨®ç¾¤ï¼Œè®“å°è©±é¢¨æ ¼èª¿æ•´æˆæ›´ç›¸åˆã€Œä»–/å¥¹ã€ä¾æ†‘ã€‚
2. å°å‘å¼å°è©±æ¨¡å‹ï¼šé€™å€‹æ¨¡å‹ä¸åƒä¸€èˆ¬çš„å›ç­”æ¨¡å‹ï¼Œå®ƒæœ‰ã€Œä¸‹ä¸€æ­¥ã€ç¯„å®šèƒ½åŠ›ï¼Œèƒ½æ ¹æ“šç”¨æˆ¶ç¾åœ¨ç‹€æ…‹ï¼Œæ¨å‹•æˆäº¤ï¼Œæˆ–æ˜¯æ¥ç¶œè³‡æ–™ï¼Œæœ‰åŠ›æå‡çœ‹æˆ¿å‹•æ¼«èˆ‡æˆæ•ˆã€‚
3. æ–‡æœ¬åˆ†å‰² & å‘é‡åŒ–æŠ€è¡“ï¼šä½¿ç”¨ FAISS èˆ‡ sentence-transformers æŠ€è¡“ï¼Œå°‡è³‡æ–™ä»˜çµ¦å‘é‡è¡¨ç¤ºï¼Œæ–¹ä¾¿æˆ‘å€‘åœ¨æ‰¾æˆ¿æ—¶æ¯”å°ç¶“é©—ã€åŒ¹é…å¥½æˆ¿ï¼Œç›¡å¯èƒ½è½‰æ›æˆåŠŸã€‚
ç¬¬å››ç« ï¼šç¨ç‰¹ç«¶çˆ­å„ªå‹¢
1. æˆ€æ„›å¼å°è©±æ¦‚å¿µï¼šæ¡ç”¨ã€Œåƒè·Ÿå¥³æœ‹å‹èªªè©±ã€çš„èªæ°£ã€Œçµ¦äºˆæ„Ÿæ€§èˆ‡åŒç†ã€çš„æˆåˆ†ï¼Œæ‰“ç ´å‚³çµ± bot å½±åƒç„¡æ°£ã€èªçœŸçš„é©—ç·´ã€‚
2. å°ˆæ¥­çš„æˆ¿åœ°ç”¢åˆ†ææŠ€è¡“ï¼šæ­é…æˆ‘å€‘åœ˜éšŠçš„æˆ¿åœ°ç”¢å„ªå‹¢ï¼Œè¼‰å…¥å¾ˆå¤šé‡å°åœ°å€ã€ç”¢æ¬Šã€ç¶“é©—å…§å®¹ï¼Œè®“å°è©±ä¸å†æ²’æœ‰åº•æ°´ï¼Œæœ‰èƒ½åŠ›æä¾›å°ˆæ¥­æŒ‡å°ã€‚
ç¬¬äº”ç« ï¼šé æœŸæ•ˆç›Š
* ä¸Šç·š 3 å€‹æœˆå…§ï¼Œçœ‹æˆ¿é ç´„ç‡æé«˜ 40%
* åº—é¢èªè­˜ä½çš„ç”¨æˆ¶ï¼Œå°è©±ä¸‹å–®æˆåŠŸç‡å¢åŠ å€‹ 3 å€
* æä¾›å¼·åŒ–ç‰ˆçš„ã€Œèªè­˜é©—è­‰ã€ï¼Œå…è²»æª¢è¦½åˆæ³•æ€§è³‡æ–™ï¼Œå¢å¼·å°åº—åº—ä¹‹é–“çš„ä¿¡ä»»
ç¬¬å…­ç« ï¼šä½¿ç”¨æƒ…å¢ƒç¯„ä¾‹
LINE å°è©±ç¼ºå¯è¦‹ï¼š
ç”¨æˆ¶ï¼šæˆ‘æƒ³æ‰¾æ±å€çš„å…©æˆ¿ä¸€åº«ï¼Œæœ€å¥½æœ‰å€åŸŸç…§ã€‚
AIï¼šå¥½å–”ï½æ±å€çš„ç¸½åˆå‹æˆ¿åº«æœ€åˆé©å¸¶å­©å­åŒä½ï¼Œæˆ‘é¦–æ¨æ–°ä¸Šå¸‚çš„ XX å·¥ç¨‹æˆ¿ï¼Œè¦çœ‹åœ–å—ï¼Ÿ
ç”¨æˆ¶ï¼šå¥½å–”
AIï¼šåœ–ç‰‡é€ä¸Šã€‚é å¹…ä¸‹æ–¹æœ‰é ç´„åé¡ï¼Œéœ€è¦å¹«ä½ ç¶“ç´€åˆ—ç·šå—ï¼Ÿ
"""
    chunks = splitter.split_text(LARGE_TEXT)
    return [Document(page_content=chunk) for chunk in chunks]

# === STEP 4: å»ºç«‹å‘é‡è³‡æ–™åº« ===
def create_vectorstore(chunks, embedding_model):
    return FAISS.from_documents(chunks, embedding_model)


# === STEP 5: å•ç­”éšæ®µï¼šæŸ¥è©¢ FAISS ä¸¦é¤µçµ¦ GPT ===
def ask_gpt_with_context(query: str, vectorstore: FAISS) -> str:
    docs = vectorstore.similarity_search(query, k=3)
    context = "\n\n".join([doc.page_content for doc in docs])
    system_prompt = "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çŸ¥è­˜åŠ©ç†ï¼Œè«‹æ ¹æ“šä¸‹åˆ—å…§å®¹å›ç­”å•é¡Œï¼š"
    user_prompt = f"å…§å®¹ï¼š\n{context}\n\nå•é¡Œï¼š{query}"
    
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.98,
        max_tokens=300,
    )
    return response["choices"][0]["message"]["content"].strip()





app = Flask(__name__)






@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    print(f"[Webhook æ¥æ”¶åˆ°è¨Šæ¯] Body:\n{body}")  # å°å‡ºè¨Šæ¯å…§å®¹ä»¥ç¢ºèª

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        print("[ç°½ç« éŒ¯èª¤] Signature ç„¡æ•ˆ")
        abort(400)

    return 'OK'

@app.before_first_request
def build_vectorstore():
    global vectorstore
    if vectorstore is None:  # ç¢ºä¿åªå»ºä¸€æ¬¡
        print("ğŸ” è¼‰å…¥è³‡æ–™èˆ‡å»ºç«‹å‘é‡åº«...")
        embeddings = load_embedding_model()
        print("ğŸ” è®€å– TXT æª” ä¸¦åˆ‡å‰²...")
        docs = load_static_document()
        print("ğŸ” å»ºç«‹å‘é‡è³‡æ–™åº«...") 
        vectorstore = FAISS.from_documents(docs, embeddings)




@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    global vectorstore
    user_input = event.message.text
    user_id = event.source.user_id

    if vectorstore is None:
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="ç³»çµ±å‰›å•Ÿå‹•ï¼Œæ­£åœ¨è¼‰å…¥çŸ¥è­˜åº«ï¼Œè«‹ç¨å¾Œå¹¾ç§’å†è©¦ ğŸ™")
        )
        return
    
    try:          
        # æ‰€æœ‰è¨Šæ¯éƒ½ç”¨å‘é‡è³‡æ–™åº«æŸ¥æ‰¾å…§å®¹ + GPT å›ç­”
        reply = ask_gpt_with_context(user_input, vectorstore)

        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=reply)
        )

        print(f"[ä½¿ç”¨è€… ID] {user_id}")
        print(f"[ä½¿ç”¨è€…æå•] {user_input}")
        print(f"[AI å›ç­”] {reply}")

    except Exception as e:
        print("âš ï¸ éŒ¯èª¤ç™¼ç”Ÿï¼š", e)
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="æŠ±æ­‰ï½å‰›å‰›æœ‰é»å°ç‹€æ³ï¼Œå“¥å“¥å¯ä»¥å†èªªä¸€æ¬¡å—ï¼Ÿ")
        )



if __name__ == "__main__":
    print("[å•Ÿå‹•] Flask App åŸ·è¡Œä¸­")
    app.run(host="0.0.0.0", port=5000)






