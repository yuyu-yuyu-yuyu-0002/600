from flask import Flask, request, abort 
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
import openai
import traceback
import os
import json
import random 
from datetime import datetime
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document 
from mega import Mega





os.environ["TOKENIZERS_PARALLELISM"] = "false"


# GPT API Key è¨­å®šï¼ˆopenai 0.28.1 å¯«æ³•ï¼‰
openai.api_key = 'sk-kVraVp5JrS0q3DLd1202F329D8C943938cAfDa071f966b29'
openai.api_base = 'https://free.v36.cm/v1'  # è‡ªè¨‚ API server URL


# LINE è¨­å®š
CHANNEL_SECRET = '74630b154d9d0cf1823c5c32db2bcf4f'
CHANNEL_ACCESS_TOKEN = 'iqYgdqANm0V1UVbC+0jYZqXQNATimJvJRU+esv0RR5TlngqFDmytCT3aVyiyW3mj2BZBoRK6UYoAY8Y2D1L2iVizgzRwU3Q2QblOcdFlf58fK70AZIJ+TtCyb+zvjlwHcEn0TubFwY851pNcJVOEiwdB04t89/1O/w1cDnyilFU='


line_bot_api = LineBotApi(CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(CHANNEL_SECRET)

vectorstore = None


def download_txt_from_mega(filename: str): 
    print("ğŸ” ç™»å…¥ MEGA ä¸¦ä¸‹è¼‰ .txt æª”æ¡ˆ...")

    m = Mega()
    m.login(MEGA_EMAIL, MEGA_PASSWORD)
    files = m.get_files()

    for file_id, file in files.items():
        try:
            attrib = file.get("a")
            if isinstance(attrib, dict):
                name = attrib.get("n")
                if name == filename:
                    m.download(file, dest_path=".", dest_filename=filename)
                    print(f"âœ… æˆåŠŸä¸‹è¼‰ï¼š{filename}")
                    return
        except Exception as e:
            print(f"âš ï¸ æª¢æŸ¥æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    raise FileNotFoundError(f"âŒ åœ¨ MEGA æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{filename}")



    
def load_embedding_model():
    return HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L3-v2")

# === STEP 2: è®€å– TXT æª” ä¸¦åˆ‡å‰² ===
def load_txt_documents(filepath: str):
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read()
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_text(text)
    return [Document(page_content=chunk) for chunk in chunks]

# === STEP 4: å»ºç«‹å‘é‡è³‡æ–™åº« ===
def create_vectorstore(chunks, embedding_model):
    return FAISS.from_documents(chunks, embedding_model)

# === STEP 5: å•ç­”éšæ®µï¼šæŸ¥è©¢ FAISS ä¸¦é¤µçµ¦ GPT ===
def ask_gpt_with_context(query: str, vectorstore: FAISS) -> str:
    docs = vectorstore.similarity_search(query, k=3)
    context = "\n\n".join([doc.page_content for doc in docs])
    system_prompt = "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çŸ¥è­˜åŠ©ç†ï¼Œè«‹æ ¹æ“šä¸‹åˆ—å…§å®¹å›ç­”å•é¡Œï¼š"
    user_prompt = f"å…§å®¹ï¼š\n{context}\n\nå•é¡Œï¼š{query}"
    
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.98,
        max_tokens=300,
    )
    return response["choices"][0]["message"]["content"].strip()





app = Flask(__name__)


MEGA_EMAIL = os.environ.get("MEGA_EMAIL")
MEGA_PASSWORD = os.environ.get("MEGA_PASSWORD")




@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    print(f"[Webhook æ¥æ”¶åˆ°è¨Šæ¯] Body:\n{body}")  # å°å‡ºè¨Šæ¯å…§å®¹ä»¥ç¢ºèª

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        print("[ç°½ç« éŒ¯èª¤] Signature ç„¡æ•ˆ")
        abort(400)

    return 'OK'

@app.before_first_request
def build_vectorstore():
    global vectorstore
    if vectorstore is None:  # ç¢ºä¿åªå»ºä¸€æ¬¡
        
        print("ğŸ” ç™»å…¥ MEGA ä¸¦ä¸‹è¼‰ .txt æª”æ¡ˆ...")
        download_txt_from_mega("text.txt")
        print("âœ… ä¸‹è¼‰å®Œæˆï¼štext.txt")

        # âœ… é€™è£¡åŠ å…¥æª¢æŸ¥
        if not os.path.exists("text.txt"):
             raise FileNotFoundError("text.txt ä¸å­˜åœ¨")
        if os.stat("text.txt").st_size == 0:
            raise ValueError("text.txt æ˜¯ç©ºçš„")

        print("ğŸ“„ è®€å–ä¸¦è™•ç† text.txt")
      
        print("ğŸ” è¼‰å…¥è³‡æ–™èˆ‡å»ºç«‹å‘é‡åº«...")
        embeddings = load_embedding_model()
        print("ğŸ” è®€å– TXT æª” ä¸¦åˆ‡å‰²...")
        docs = load_txt_documents("text.txt")
        print("ğŸ” å»ºç«‹å‘é‡è³‡æ–™åº«...") 
        vectorstore = FAISS.from_documents(docs, embeddings)
        print("âœ… å‘é‡è³‡æ–™åº«å»ºç«‹å®Œæˆ")

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    global vectorstore
    user_input = event.message.text
    user_id = event.source.user_id

    if vectorstore is None:
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="ç³»çµ±å‰›å•Ÿå‹•ï¼Œæ­£åœ¨è¼‰å…¥çŸ¥è­˜åº«ï¼Œè«‹ç¨å¾Œå¹¾ç§’å†è©¦ ğŸ™")
        )
        return
    
    try:          
        # æ‰€æœ‰è¨Šæ¯éƒ½ç”¨å‘é‡è³‡æ–™åº«æŸ¥æ‰¾å…§å®¹ + GPT å›ç­”
        reply = ask_gpt_with_context(user_input, vectorstore)

        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=reply)
        )

        print(f"[ä½¿ç”¨è€… ID] {user_id}")
        print(f"[ä½¿ç”¨è€…æå•] {user_input}")
        print(f"[AI å›ç­”] {reply}")

    except Exception as e:
        print("âš ï¸ éŒ¯èª¤ç™¼ç”Ÿï¼š", e)
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="æŠ±æ­‰ï½å‰›å‰›æœ‰é»å°ç‹€æ³ï¼Œå“¥å“¥å¯ä»¥å†èªªä¸€æ¬¡å—ï¼Ÿ")
        )



if __name__ == "__main__":
    print("[å•Ÿå‹•] Flask App åŸ·è¡Œä¸­")
    app.run(host="0.0.0.0", port=5000)






